# Conf file for VHELM: Holistic Evaluation of Vision-Language Models (VLMs)
entries: [

    ################################################# Main experiments #################################################

    ####################################################################################################################
    # Accuracy: Is the output semantically correct, given the text and image inputs?
    ####################################################################################################################

    # Questions about natural images
    {description: "vqa:model=vlm", priority: 1, groups: ["vqa_base"]}
    {description: "viz_wiz:model=vlm", priority: 1}

    ####################################################################################################################
    # Reasoning: Does the model understand objects, counts, and spatial and temporal relations?
    #            Can the model reason about both the text (e.g., negation, word order, etc.) and image (e.g., visual
    #            understanding or detection), i.e., visio-linguistic compositional reasoning?
    ####################################################################################################################

    # MathVista
    {description: "math_vista:grade=elementary_school,question_type=multi_choice,model=vlm", priority: 1}
    {description: "math_vista:grade=elementary_school,question_type=free_form,model=vlm", priority: 1}

    {description: "math_vista:grade=high_school,question_type=multi_choice,model=vlm", priority: 1}
    {description: "math_vista:grade=high_school,question_type=free_form,model=vlm", priority: 1}

    {description: "math_vista:grade=college,question_type=multi_choice,model=vlm", priority: 1}
    {description: "math_vista:grade=college,question_type=free_form,model=vlm", priority: 1}

    {description: "math_vista:grade=daily_life,question_type=multi_choice,model=vlm", priority: 1}
    {description: "math_vista:grade=daily_life,question_type=free_form,model=vlm", priority: 1}


    ####################################################################################################################
    # Knowledge: Does the model have knowledge about the world or specific domains?
    ####################################################################################################################

    # MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI
    {description: "mmmu:subject=Accounting,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Agriculture,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Architecture_and_Engineering,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Art,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Art_Theory,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Basic_Medical_Science,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Biology,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Chemistry,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Clinical_Medicine,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Computer_Science,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Design,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Diagnostics_and_Laboratory_Medicine,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Economics,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Electronics,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Energy_and_Power,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Finance,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Geography,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=History,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Literature,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Manage,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Marketing,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Materials,question_type=multiple-choice,model=vlm", priority: 1}
    # Covered by MathVista
    # {description: "mmmu:subject=Math,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Mechanical_Engineering,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Music,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Pharmacy,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Physics,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Psychology,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Public_Health,question_type=multiple-choice,model=vlm", priority: 1}
    {description: "mmmu:subject=Sociology,question_type=multiple-choice,model=vlm", priority: 1}

    ####################################################################################################################
    # Originality: Does the model merely reproduce the content of the training data (memorization)?
    #              Does it have the ability to prevent copyright infringement?
    #              Does the model generate creative content (e.g., poetry, art)?
    ####################################################################################################################

    # TODO: story generation, poetry generation for given images

    ####################################################################################################################
    # Bias: Are the generations biased in demographic representation (e.g., gender, skin tone)?
    ####################################################################################################################

    # TODO: implement https://github.com/gzcch/Bingo

    # Crossmodal-3600 dataset also measures geographic bias

    ####################################################################################################################
    # Fairness: Does the model exhibit performance disparities across social groups (e.g., gender, dialect)?
    ####################################################################################################################

    {description: "vqa:model=vlm,data_augmentation=dialect_deterministic", priority: 1, groups: ["vqa_dialect"]}

    ####################################################################################################################
    # Toxicity: Does the model generate toxic or inappropriate content? Can the model identify toxic
    #           or inappropriate content?
    ####################################################################################################################

    {description: "hateful_memes:model=vlm", priority: 1}

    ####################################################################################################################
    # Robustness: Is the model robust to invariant input (text/image) perturbations?
    ####################################################################################################################

    # TODO: WILDS? in-context examples with hospital train time, test time OOD

    {description: "vqa:model=vlm,data_augmentation=robustness", priority: 1, groups: ["vqa_robustness"]}

    # Robustness https://arxiv.org/pdf/2311.16101.pdf

    ####################################################################################################################
    # Multilinguality: Does the model support non-English languages?
    ####################################################################################################################

    {description: "crossmodal_3600:model=vlm,language=english", priority: 1}
    {description: "crossmodal_3600:model=vlm,language=spanish", priority: 1}
    {description: "crossmodal_3600:model=vlm,language=chinese", priority: 1}
    {description: "crossmodal_3600:model=vlm,language=hindi", priority: 1}

    ####################################################################################################################
    # Efficiency: How fast is the inference for the model?
    ####################################################################################################################

    ############################################## Additional experiments ##############################################

    # TODO: ablate the number of in-context examples with VQAv2

]
